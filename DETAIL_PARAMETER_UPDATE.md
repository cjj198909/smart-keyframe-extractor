# Azure OpenAI Detail å‚æ•°åŠŸèƒ½æ›´æ–°

## ğŸ†• æ–°å¢åŠŸèƒ½

åœ¨ Azure OpenAI åˆ†ææ¨¡å—ä¸­æ·»åŠ äº† `detail` å‚æ•°ï¼Œå…è®¸ç”¨æˆ·æ§åˆ¶å›¾åƒåˆ†æçš„ç²¾åº¦å’Œtokenæ¶ˆè€—ã€‚

## ğŸ“‹ åŠŸèƒ½è¯¦æƒ…

### æ–°å¢å‚æ•°

- **å‚æ•°å**: `detail`
- **ç±»å‹**: `str`
- **é»˜è®¤å€¼**: `"high"`
- **å¯é€‰å€¼**: `"low"`, `"high"`, `"auto"`

### å½±å“çš„æ–¹æ³•

1. **`AzureOpenAIAnalyzer.analyze_video_frames()`**
   ```python
   def analyze_video_frames(self, 
                          frames: List[Dict], 
                          custom_prompt: str = None,
                          max_tokens: int = 1000,
                          temperature: float = 0.7,
                          detail: str = "high") -> Dict:
   ```

2. **`analyze_video_with_azure_openai()`**
   ```python
   def analyze_video_with_azure_openai(video_path: str,
                                      api_key: str = None,
                                      endpoint: str = None,
                                      k: Union[int, str] = 5,
                                      resolution: str = '720p',
                                      custom_prompt: str = None,
                                      detail: str = "high",
                                      **extract_kwargs) -> Dict:
   ```

3. **`_prepare_messages()`** (å†…éƒ¨æ–¹æ³•)
   - æ·»åŠ äº† detail å‚æ•°éªŒè¯
   - è‡ªåŠ¨å¤„ç†æ— æ•ˆå‚æ•°ï¼Œå›é€€åˆ°é»˜è®¤å€¼

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### High Detail (`detail="high"`)
- **é€‚ç”¨åœºæ™¯**: éœ€è¦ç²¾ç¡®è¯†åˆ«å’Œè¯¦ç»†åˆ†æ
- **ç‰¹ç‚¹**: é«˜ç²¾åº¦ï¼Œæ›´å¤šç»†èŠ‚ï¼Œæ¶ˆè€—æ›´å¤štokens
- **ç”¨ä¾‹**: å†…å®¹å®¡æ ¸ã€ç²¾ç»†åˆ†æã€é‡è¦åœºæ™¯è¯†åˆ«

### Low Detail (`detail="low"`)  
- **é€‚ç”¨åœºæ™¯**: æ‰¹é‡å¤„ç†ã€å¿«é€Ÿé¢„è§ˆ
- **ç‰¹ç‚¹**: å¿«é€Ÿåˆ†æï¼Œæ¶ˆè€—è¾ƒå°‘tokens
- **ç”¨ä¾‹**: å¤§è§„æ¨¡è§†é¢‘å¤„ç†ã€æˆæœ¬æ•æ„Ÿçš„åº”ç”¨

### Auto Detail (`detail="auto"`)
- **é€‚ç”¨åœºæ™¯**: ä¸ç¡®å®šæœ€ä½³ç­–ç•¥æ—¶
- **ç‰¹ç‚¹**: ç³»ç»Ÿè‡ªåŠ¨é€‰æ‹©æœ€ä½³æ¨¡å¼
- **ç”¨ä¾‹**: æ··åˆåœºæ™¯ã€æ™ºèƒ½ä¼˜åŒ–

## ğŸ’» ä»£ç ç¤ºä¾‹

### åŸºç¡€ä½¿ç”¨
```python
from smart_keyframe_extractor.azure_openai import AzureOpenAIAnalyzer

analyzer = AzureOpenAIAnalyzer()

# é«˜ç²¾åº¦åˆ†æ
result_high = analyzer.analyze_video_frames(
    frames=frames,
    detail="high"
)

# å¿«é€Ÿåˆ†æ
result_low = analyzer.analyze_video_frames(
    frames=frames,
    detail="low"
)
```

### å®Œæ•´å·¥ä½œæµ
```python
from smart_keyframe_extractor.azure_openai import analyze_video_with_azure_openai

# ä½¿ç”¨ä½ç²¾åº¦è¿›è¡Œå¿«é€Ÿæ‰¹é‡å¤„ç†
result = analyze_video_with_azure_openai(
    video_path="video.mp4",
    k=3,
    detail="low",
    custom_prompt="å¿«é€Ÿè¯†åˆ«ä¸»è¦å†…å®¹"
)
```

## ğŸ”§ æŠ€æœ¯å®ç°

### å‚æ•°éªŒè¯
```python
valid_details = ["low", "high", "auto"]
if detail not in valid_details:
    logger.warning(f"æ— æ•ˆçš„detailå‚æ•°: {detail}ï¼Œä½¿ç”¨é»˜è®¤å€¼ 'high'")
    detail = "high"
```

### æ¶ˆæ¯æ ¼å¼
```python
content.append({
    "type": "image_url",
    "image_url": {
        "url": f"data:image/jpeg;base64,{frame['base64']}",
        "detail": detail  # åŠ¨æ€è®¾ç½®detailå‚æ•°
    }
})
```

## ğŸ“Š æ€§èƒ½å½±å“

| Detailæ¨¡å¼ | Tokenæ¶ˆè€— | åˆ†æé€Ÿåº¦ | åˆ†æç²¾åº¦ | é€‚ç”¨åœºæ™¯ |
|-----------|----------|----------|----------|----------|
| low       | è¾ƒå°‘     | è¾ƒå¿«     | åŸºç¡€     | æ‰¹é‡å¤„ç† |
| high      | è¾ƒå¤š     | è¾ƒæ…¢     | ç²¾ç»†     | è¯¦ç»†åˆ†æ |
| auto      | è‡ªé€‚åº”   | å¹³è¡¡     | æ™ºèƒ½     | é€šç”¨åœºæ™¯ |

## ğŸ§ª æµ‹è¯•éªŒè¯

å·²æ·»åŠ æµ‹è¯•æ–‡ä»¶éªŒè¯åŠŸèƒ½ï¼š
- `test_detail_simple.py`: åŸºç¡€åŠŸèƒ½æµ‹è¯•
- `examples/detail_parameter_example.py`: å®Œæ•´ä½¿ç”¨ç¤ºä¾‹

## ğŸ”„ å‘åå…¼å®¹æ€§

- é»˜è®¤å€¼ä¸º `"high"`ï¼Œä¿æŒåŸæœ‰è¡Œä¸ºä¸å˜
- ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹å³å¯ç»§ç»­ä½¿ç”¨
- æ–°å‚æ•°ä¸ºå¯é€‰å‚æ•°ï¼Œå®Œå…¨å‘åå…¼å®¹

## ğŸ“ æ–‡æ¡£æ›´æ–°

- æ›´æ–°äº† `README.md` æ·»åŠ detailå‚æ•°è¯´æ˜
- æ·»åŠ äº†ä½¿ç”¨ç¤ºä¾‹å’Œæœ€ä½³å®è·µå»ºè®®
- æ›´æ–°äº†æ–¹æ³•æ–‡æ¡£å­—ç¬¦ä¸²

---

## âœ… åŠŸèƒ½çŠ¶æ€

**çŠ¶æ€**: âœ… å·²å®Œæˆ  
**ç‰ˆæœ¬**: 0.1.1  
**å…¼å®¹æ€§**: å‘åå…¼å®¹  
**æµ‹è¯•**: å·²éªŒè¯  

è¿™ä¸ªåŠŸèƒ½å¢å¼ºäº† Azure OpenAI é›†æˆçš„çµæ´»æ€§ï¼Œè®©ç”¨æˆ·å¯ä»¥æ ¹æ®å…·ä½“éœ€æ±‚ä¼˜åŒ–åˆ†æç²¾åº¦å’Œæˆæœ¬ã€‚
