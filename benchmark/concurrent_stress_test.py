#!/usr/bin/env python3
"""
å¹¶å‘å‹åŠ›æµ‹è¯•å·¥å…· - æ”¯æŒå¤šè§†é¢‘æ–‡ä»¶å¹¶å‘å¤„ç†
é€‚åˆäº‘æœåŠ¡å™¨å¤§è§„æ¨¡å‹åŠ›æµ‹è¯•
"""

import time
import psutil
import os
import sys
import threading
import statistics
import json
import concurrent.futures
import queue
import random
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import logging
import signal
from dataclasses import dataclass
import glob
import cv2

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))
from smart_keyframe_extractor.extractor import extract_top_k_keyframes

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(threadName)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class TestTask:
    """æµ‹è¯•ä»»åŠ¡æ•°æ®ç±»"""
    video_path: str
    config: Dict
    task_id: str
    thread_id: int


@dataclass
class TestResult:
    """æµ‹è¯•ç»“æœæ•°æ®ç±»"""
    task_id: str
    thread_id: int
    video_path: str
    config: Dict
    success: bool
    execution_time: float
    memory_usage: float
    keyframes_extracted: int
    error: Optional[str]
    timestamp: str
    video_size_mb: float
    video_duration: float
    fps_processed: float


class ConcurrentStressTester:
    """å¹¶å‘å‹åŠ›æµ‹è¯•å™¨"""
    
    def __init__(self, output_dir: str = "benchmark_results", max_workers: int = None):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.max_workers = max_workers or min(32, (os.cpu_count() or 1) + 4)
        self.results = []
        self.system_info = self._get_system_info()
        self.test_videos = []
        self.stop_event = threading.Event()
        self.stats_lock = threading.Lock()
        self.task_counter = 0
        
        # æ€§èƒ½ç›‘æ§
        self.performance_monitor = PerformanceMonitor()
        
        print(f"ğŸš€ å¹¶å‘å‹åŠ›æµ‹è¯•å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“ ç»“æœè¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"ğŸ”§ æœ€å¤§å¹¶å‘æ•°: {self.max_workers}")
        print(f"ğŸ’» ç³»ç»Ÿä¿¡æ¯: {self.system_info}")
        
        # æ³¨å†Œä¿¡å·å¤„ç†å™¨
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
    
    def _signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å™¨ï¼Œä¼˜é›…é€€å‡º"""
        logger.warning(f"æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨åœæ­¢æµ‹è¯•...")
        self.stop_event.set()
    
    def _get_system_info(self) -> Dict:
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        return {
            "cpu_count": psutil.cpu_count(),
            "cpu_logical_count": psutil.cpu_count(logical=True),
            "cpu_freq": psutil.cpu_freq().current if psutil.cpu_freq() else "Unknown",
            "memory_total": psutil.virtual_memory().total / (1024**3),  # GB
            "memory_available": psutil.virtual_memory().available / (1024**3),  # GB
            "disk_free": psutil.disk_usage('/').free / (1024**3),  # GB
            "python_version": sys.version,
            "platform": sys.platform,
            "hostname": os.uname().nodename if hasattr(os, 'uname') else "unknown",
            "timestamp": datetime.now().isoformat()
        }
    
    def discover_video_files(self, video_dirs: List[str], extensions: List[str] = None) -> List[str]:
        """å‘ç°æŒ‡å®šç›®å½•ä¸­çš„è§†é¢‘æ–‡ä»¶"""
        if extensions is None:
            extensions = ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm']
        
        video_files = []
        for video_dir in video_dirs:
            video_path = Path(video_dir)
            if not video_path.exists():
                logger.warning(f"è§†é¢‘ç›®å½•ä¸å­˜åœ¨: {video_dir}")
                continue
            
            logger.info(f"æ‰«æè§†é¢‘ç›®å½•: {video_dir}")
            for ext in extensions:
                pattern = f"**/*{ext}"
                files = list(video_path.glob(pattern))
                video_files.extend([str(f) for f in files])
                logger.info(f"æ‰¾åˆ° {len(files)} ä¸ª {ext} æ–‡ä»¶")
        
        self.test_videos = video_files
        logger.info(f"æ€»å…±å‘ç° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
        return video_files
    
    def get_video_info(self, video_path: str) -> Dict:
        """è·å–è§†é¢‘æ–‡ä»¶ä¿¡æ¯"""
        try:
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                return {"error": "æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶"}
            
            info = {
                "total_frames": int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),
                "fps": cap.get(cv2.CAP_PROP_FPS),
                "width": int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),
                "height": int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),
                "file_size_mb": os.path.getsize(video_path) / (1024 * 1024)
            }
            info["duration"] = info["total_frames"] / info["fps"] if info["fps"] > 0 else 0
            cap.release()
            return info
        except Exception as e:
            return {"error": str(e)}
    
    def process_single_video(self, task: TestTask) -> TestResult:
        """å¤„ç†å•ä¸ªè§†é¢‘çš„æµ‹è¯•ä»»åŠ¡"""
        thread_name = threading.current_thread().name
        logger.info(f"[{thread_name}] å¼€å§‹å¤„ç†ä»»åŠ¡ {task.task_id}: {os.path.basename(task.video_path)}")
        
        # è·å–è§†é¢‘ä¿¡æ¯
        video_info = self.get_video_info(task.video_path)
        if "error" in video_info:
            return TestResult(
                task_id=task.task_id,
                thread_id=task.thread_id,
                video_path=task.video_path,
                config=task.config,
                success=False,
                execution_time=0.0,
                memory_usage=0.0,
                keyframes_extracted=0,
                error=video_info["error"],
                timestamp=datetime.now().isoformat(),
                video_size_mb=0.0,
                video_duration=0.0,
                fps_processed=0.0
            )
        
        # ç›‘æ§èµ„æºä½¿ç”¨
        process = psutil.Process()
        memory_before = process.memory_info().rss / (1024**2)  # MB
        
        start_time = time.time()
        
        try:
            # æ‰§è¡Œå…³é”®å¸§æå–
            result = extract_top_k_keyframes(
                video_path=task.video_path,
                k=task.config.get('k', 5),
                resolution=task.config.get('resolution', 'original'),
                return_base64=task.config.get('return_base64', False),
                save_files=False
            )
            
            end_time = time.time()
            execution_time = end_time - start_time
            memory_after = process.memory_info().rss / (1024**2)  # MB
            
            # åˆ†æç»“æœ
            success = 'frames' in result and len(result['frames']) > 0
            keyframes_extracted = len(result.get('frames', []))
            
            test_result = TestResult(
                task_id=task.task_id,
                thread_id=task.thread_id,
                video_path=task.video_path,
                config=task.config,
                success=success,
                execution_time=execution_time,
                memory_usage=memory_after - memory_before,
                keyframes_extracted=keyframes_extracted,
                error=None,
                timestamp=datetime.now().isoformat(),
                video_size_mb=video_info.get('file_size_mb', 0),
                video_duration=video_info.get('duration', 0),
                fps_processed=video_info.get('total_frames', 0) / execution_time if execution_time > 0 else 0
            )
            
            logger.info(f"[{thread_name}] ä»»åŠ¡ {task.task_id} å®Œæˆ: "
                       f"{execution_time:.2f}s, {keyframes_extracted}å¸§")
            
        except Exception as e:
            end_time = time.time()
            execution_time = end_time - start_time
            
            test_result = TestResult(
                task_id=task.task_id,
                thread_id=task.thread_id,
                video_path=task.video_path,
                config=task.config,
                success=False,
                execution_time=execution_time,
                memory_usage=0.0,
                keyframes_extracted=0,
                error=str(e),
                timestamp=datetime.now().isoformat(),
                video_size_mb=video_info.get('file_size_mb', 0),
                video_duration=video_info.get('duration', 0),
                fps_processed=0.0
            )
            
            logger.error(f"[{thread_name}] ä»»åŠ¡ {task.task_id} å¤±è´¥: {e}")
        
        return test_result
    
    def run_concurrent_test(self, 
                           video_dirs: List[str],
                           test_configs: List[Dict],
                           iterations: int = 1,
                           max_concurrent: int = None,
                           random_order: bool = True) -> List[TestResult]:
        """è¿è¡Œå¹¶å‘å‹åŠ›æµ‹è¯•"""
        
        logger.info("ğŸš€ å¼€å§‹å¹¶å‘å‹åŠ›æµ‹è¯•")
        
        # å‘ç°è§†é¢‘æ–‡ä»¶
        video_files = self.discover_video_files(video_dirs)
        if not video_files:
            logger.error("æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶")
            return []
        
        # ç”Ÿæˆæµ‹è¯•ä»»åŠ¡
        tasks = []
        for iteration in range(iterations):
            for video_path in video_files:
                for config_idx, config in enumerate(test_configs):
                    task_id = f"iter_{iteration+1}_config_{config_idx+1}_video_{len(tasks)+1}"
                    task = TestTask(
                        video_path=video_path,
                        config=config,
                        task_id=task_id,
                        thread_id=len(tasks) % self.max_workers
                    )
                    tasks.append(task)
        
        # éšæœºæ‰“ä¹±ä»»åŠ¡é¡ºåº
        if random_order:
            random.shuffle(tasks)
        
        total_tasks = len(tasks)
        logger.info(f"ç”Ÿæˆ {total_tasks} ä¸ªæµ‹è¯•ä»»åŠ¡")
        logger.info(f"è§†é¢‘æ–‡ä»¶: {len(video_files)} ä¸ª")
        logger.info(f"é…ç½®æ–¹æ¡ˆ: {len(test_configs)} ä¸ª")
        logger.info(f"è¿­ä»£æ¬¡æ•°: {iterations} æ¬¡")
        
        # å¯åŠ¨æ€§èƒ½ç›‘æ§
        self.performance_monitor.start()
        
        # æ‰§è¡Œå¹¶å‘æµ‹è¯•
        results = []
        start_time = time.time()
        completed_tasks = 0
        
        max_workers = max_concurrent or self.max_workers
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_task = {
                executor.submit(self.process_single_video, task): task
                for task in tasks
            }
            
            # æ”¶é›†ç»“æœ
            for future in concurrent.futures.as_completed(future_to_task):
                if self.stop_event.is_set():
                    logger.warning("æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œå–æ¶ˆå‰©ä½™ä»»åŠ¡")
                    break
                
                task = future_to_task[future]
                try:
                    result = future.result()
                    results.append(result)
                    
                    with self.stats_lock:
                        completed_tasks += 1
                        progress = completed_tasks / total_tasks * 100
                        elapsed = time.time() - start_time
                        eta = elapsed / completed_tasks * (total_tasks - completed_tasks) if completed_tasks > 0 else 0
                        
                        logger.info(f"è¿›åº¦: {completed_tasks}/{total_tasks} ({progress:.1f}%) "
                                   f"å·²ç”¨æ—¶: {elapsed:.1f}s, é¢„è®¡å‰©ä½™: {eta:.1f}s")
                
                except Exception as e:
                    logger.error(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {e}")
        
        # åœæ­¢æ€§èƒ½ç›‘æ§
        self.performance_monitor.stop()
        
        total_time = time.time() - start_time
        logger.info(f"å¹¶å‘æµ‹è¯•å®Œæˆ: {completed_tasks}/{total_tasks} ä»»åŠ¡å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}s")
        
        # ä¿å­˜ç»“æœ
        self.results.extend(results)
        self.save_results(results, f"concurrent_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
        
        return results
    
    def run_sustained_load_test(self,
                               video_dirs: List[str],
                               test_config: Dict,
                               duration_minutes: int = 10,
                               target_qps: float = 1.0) -> List[TestResult]:
        """è¿è¡ŒæŒç»­è´Ÿè½½æµ‹è¯•"""
        
        logger.info(f"ğŸ”¥ å¼€å§‹æŒç»­è´Ÿè½½æµ‹è¯•: {duration_minutes}åˆ†é’Ÿ, ç›®æ ‡QPS: {target_qps}")
        
        # å‘ç°è§†é¢‘æ–‡ä»¶
        video_files = self.discover_video_files(video_dirs)
        if not video_files:
            logger.error("æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶")
            return []
        
        results = []
        start_time = time.time()
        end_time = start_time + (duration_minutes * 60)
        task_counter = 0
        
        # å¯åŠ¨æ€§èƒ½ç›‘æ§
        self.performance_monitor.start()
        
        def submit_task():
            nonlocal task_counter
            video_path = random.choice(video_files)
            task_id = f"sustained_load_{task_counter+1}"
            task_counter += 1
            
            task = TestTask(
                video_path=video_path,
                config=test_config,
                task_id=task_id,
                thread_id=task_counter % self.max_workers
            )
            
            return task
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            active_futures = set()
            last_submit_time = time.time()
            
            while time.time() < end_time and not self.stop_event.is_set():
                current_time = time.time()
                
                # æ ¹æ®ç›®æ ‡QPSæäº¤æ–°ä»»åŠ¡
                if current_time - last_submit_time >= (1.0 / target_qps):
                    if len(active_futures) < self.max_workers:
                        task = submit_task()
                        future = executor.submit(self.process_single_video, task)
                        active_futures.add(future)
                        last_submit_time = current_time
                        logger.debug(f"æäº¤ä»»åŠ¡ {task.task_id}, æ´»è·ƒä»»åŠ¡æ•°: {len(active_futures)}")
                
                # æ”¶é›†å®Œæˆçš„ç»“æœ
                done_futures = [f for f in active_futures if f.done()]
                for future in done_futures:
                    try:
                        result = future.result()
                        results.append(result)
                        logger.info(f"ä»»åŠ¡å®Œæˆ: {result.task_id}, "
                                   f"è€—æ—¶: {result.execution_time:.2f}s, "
                                   f"æˆåŠŸ: {result.success}")
                    except Exception as e:
                        logger.error(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {e}")
                    
                    active_futures.remove(future)
                
                # çŸ­æš‚ä¼‘çœ é¿å…CPUå ç”¨è¿‡é«˜
                time.sleep(0.01)
            
            # ç­‰å¾…å‰©ä½™ä»»åŠ¡å®Œæˆ
            logger.info(f"ç­‰å¾… {len(active_futures)} ä¸ªå‰©ä½™ä»»åŠ¡å®Œæˆ...")
            concurrent.futures.wait(active_futures, timeout=60)
            
            for future in active_futures:
                if future.done():
                    try:
                        result = future.result()
                        results.append(result)
                    except Exception as e:
                        logger.error(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {e}")
        
        # åœæ­¢æ€§èƒ½ç›‘æ§
        self.performance_monitor.stop()
        
        total_time = time.time() - start_time
        actual_qps = len(results) / total_time if total_time > 0 else 0
        
        logger.info(f"æŒç»­è´Ÿè½½æµ‹è¯•å®Œæˆ: {len(results)} ä¸ªä»»åŠ¡å®Œæˆ, "
                   f"æ€»è€—æ—¶: {total_time:.2f}s, å®é™…QPS: {actual_qps:.2f}")
        
        # ä¿å­˜ç»“æœ
        self.save_results(results, f"sustained_load_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
        
        return results
    
    def analyze_results(self, results: List[TestResult]) -> Dict:
        """åˆ†ææµ‹è¯•ç»“æœ"""
        if not results:
            return {"error": "æ²¡æœ‰æµ‹è¯•ç»“æœ"}
        
        # åŸºç¡€ç»Ÿè®¡
        total_tasks = len(results)
        successful_tasks = len([r for r in results if r.success])
        failed_tasks = total_tasks - successful_tasks
        success_rate = successful_tasks / total_tasks * 100
        
        # æ€§èƒ½ç»Ÿè®¡
        execution_times = [r.execution_time for r in results if r.success]
        memory_usages = [r.memory_usage for r in results if r.success]
        keyframes_counts = [r.keyframes_extracted for r in results if r.success]
        
        analysis = {
            "summary": {
                "total_tasks": total_tasks,
                "successful_tasks": successful_tasks,
                "failed_tasks": failed_tasks,
                "success_rate": success_rate
            },
            "performance": {
                "execution_time": {
                    "mean": statistics.mean(execution_times) if execution_times else 0,
                    "median": statistics.median(execution_times) if execution_times else 0,
                    "min": min(execution_times) if execution_times else 0,
                    "max": max(execution_times) if execution_times else 0,
                    "std": statistics.stdev(execution_times) if len(execution_times) > 1 else 0
                },
                "memory_usage": {
                    "mean": statistics.mean(memory_usages) if memory_usages else 0,
                    "median": statistics.median(memory_usages) if memory_usages else 0,
                    "min": min(memory_usages) if memory_usages else 0,
                    "max": max(memory_usages) if memory_usages else 0,
                    "std": statistics.stdev(memory_usages) if len(memory_usages) > 1 else 0
                },
                "keyframes_extracted": {
                    "mean": statistics.mean(keyframes_counts) if keyframes_counts else 0,
                    "median": statistics.median(keyframes_counts) if keyframes_counts else 0,
                    "min": min(keyframes_counts) if keyframes_counts else 0,
                    "max": max(keyframes_counts) if keyframes_counts else 0,
                    "total": sum(keyframes_counts)
                }
            },
            "system_performance": self.performance_monitor.get_stats(),
            "timestamp": datetime.now().isoformat()
        }
        
        return analysis
    
    def save_results(self, results: List[TestResult], filename_prefix: str):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        # å°†ç»“æœè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        results_dict = [
            {
                "task_id": r.task_id,
                "thread_id": r.thread_id,
                "video_path": r.video_path,
                "video_filename": os.path.basename(r.video_path),
                "config": r.config,
                "success": r.success,
                "execution_time": r.execution_time,
                "memory_usage": r.memory_usage,
                "keyframes_extracted": r.keyframes_extracted,
                "error": r.error,
                "timestamp": r.timestamp,
                "video_size_mb": r.video_size_mb,
                "video_duration": r.video_duration,
                "fps_processed": r.fps_processed
            }
            for r in results
        ]
        
        # ä¿å­˜JSONæ ¼å¼
        json_file = self.output_dir / f"{filename_prefix}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump({
                "system_info": self.system_info,
                "test_config": {
                    "max_workers": self.max_workers,
                    "total_tasks": len(results)
                },
                "results": results_dict,
                "analysis": self.analyze_results(results)
            }, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜CSVæ ¼å¼ï¼ˆä¾¿äºExcelåˆ†æï¼‰
        try:
            import pandas as pd
            csv_file = self.output_dir / f"{filename_prefix}.csv"
            df = pd.DataFrame(results_dict)
            df.to_csv(csv_file, index=False)
            logger.info(f"ç»“æœå·²ä¿å­˜: {json_file}, {csv_file}")
        except ImportError:
            logger.info(f"ç»“æœå·²ä¿å­˜: {json_file}")
    
    def print_summary(self, results: List[TestResult]):
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        analysis = self.analyze_results(results)
        
        print("\n" + "="*60)
        print("ğŸ“Š å¹¶å‘å‹åŠ›æµ‹è¯•ç»“æœæ‘˜è¦")
        print("="*60)
        
        summary = analysis["summary"]
        print(f"ğŸ“ˆ ä»»åŠ¡ç»Ÿè®¡:")
        print(f"   æ€»ä»»åŠ¡æ•°: {summary['total_tasks']}")
        print(f"   æˆåŠŸä»»åŠ¡: {summary['successful_tasks']}")
        print(f"   å¤±è´¥ä»»åŠ¡: {summary['failed_tasks']}")
        print(f"   æˆåŠŸç‡: {summary['success_rate']:.1f}%")
        
        perf = analysis["performance"]
        print(f"\nâ±ï¸  æ€§èƒ½ç»Ÿè®¡:")
        print(f"   å¹³å‡æ‰§è¡Œæ—¶é—´: {perf['execution_time']['mean']:.2f}s")
        print(f"   æ‰§è¡Œæ—¶é—´èŒƒå›´: {perf['execution_time']['min']:.2f}s - {perf['execution_time']['max']:.2f}s")
        print(f"   å¹³å‡å†…å­˜ä½¿ç”¨: {perf['memory_usage']['mean']:.1f}MB")
        print(f"   æ€»æå–å¸§æ•°: {perf['keyframes_extracted']['total']}")
        
        if "system_performance" in analysis:
            sys_perf = analysis["system_performance"]
            print(f"\nğŸ’» ç³»ç»Ÿæ€§èƒ½:")
            print(f"   å¹³å‡CPUä½¿ç”¨ç‡: {sys_perf.get('avg_cpu_percent', 0):.1f}%")
            print(f"   å¹³å‡å†…å­˜ä½¿ç”¨ç‡: {sys_perf.get('avg_memory_percent', 0):.1f}%")


class PerformanceMonitor:
    """ç³»ç»Ÿæ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self, interval: float = 1.0):
        self.interval = interval
        self.monitoring = False
        self.monitor_thread = None
        self.cpu_samples = []
        self.memory_samples = []
        self.disk_io_samples = []
        self.network_io_samples = []
    
    def start(self):
        """å¼€å§‹ç›‘æ§"""
        if self.monitoring:
            return
        
        self.monitoring = True
        self.cpu_samples = []
        self.memory_samples = []
        self.disk_io_samples = []
        self.network_io_samples = []
        
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
        logger.info("æ€§èƒ½ç›‘æ§å·²å¯åŠ¨")
    
    def stop(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=2)
        logger.info("æ€§èƒ½ç›‘æ§å·²åœæ­¢")
    
    def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        last_disk_io = psutil.disk_io_counters()
        last_net_io = psutil.net_io_counters()
        
        while self.monitoring:
            try:
                # CPUä½¿ç”¨ç‡
                cpu_percent = psutil.cpu_percent(interval=None)
                self.cpu_samples.append(cpu_percent)
                
                # å†…å­˜ä½¿ç”¨ç‡
                memory = psutil.virtual_memory()
                self.memory_samples.append(memory.percent)
                
                # ç£ç›˜IO
                current_disk_io = psutil.disk_io_counters()
                if last_disk_io:
                    disk_read_speed = (current_disk_io.read_bytes - last_disk_io.read_bytes) / self.interval
                    disk_write_speed = (current_disk_io.write_bytes - last_disk_io.write_bytes) / self.interval
                    self.disk_io_samples.append({
                        'read_speed': disk_read_speed,
                        'write_speed': disk_write_speed
                    })
                last_disk_io = current_disk_io
                
                # ç½‘ç»œIO
                current_net_io = psutil.net_io_counters()
                if last_net_io:
                    net_recv_speed = (current_net_io.bytes_recv - last_net_io.bytes_recv) / self.interval
                    net_sent_speed = (current_net_io.bytes_sent - last_net_io.bytes_sent) / self.interval
                    self.network_io_samples.append({
                        'recv_speed': net_recv_speed,
                        'sent_speed': net_sent_speed
                    })
                last_net_io = current_net_io
                
                time.sleep(self.interval)
                
            except Exception as e:
                logger.error(f"æ€§èƒ½ç›‘æ§å¼‚å¸¸: {e}")
                break
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡æ•°æ®"""
        stats = {}
        
        if self.cpu_samples:
            stats['avg_cpu_percent'] = statistics.mean(self.cpu_samples)
            stats['max_cpu_percent'] = max(self.cpu_samples)
            stats['min_cpu_percent'] = min(self.cpu_samples)
        
        if self.memory_samples:
            stats['avg_memory_percent'] = statistics.mean(self.memory_samples)
            stats['max_memory_percent'] = max(self.memory_samples)
            stats['min_memory_percent'] = min(self.memory_samples)
        
        if self.disk_io_samples:
            read_speeds = [s['read_speed'] for s in self.disk_io_samples]
            write_speeds = [s['write_speed'] for s in self.disk_io_samples]
            stats['avg_disk_read_speed'] = statistics.mean(read_speeds) / (1024*1024)  # MB/s
            stats['avg_disk_write_speed'] = statistics.mean(write_speeds) / (1024*1024)  # MB/s
        
        if self.network_io_samples:
            recv_speeds = [s['recv_speed'] for s in self.network_io_samples]
            sent_speeds = [s['sent_speed'] for s in self.network_io_samples]
            stats['avg_network_recv_speed'] = statistics.mean(recv_speeds) / (1024*1024)  # MB/s
            stats['avg_network_sent_speed'] = statistics.mean(sent_speeds) / (1024*1024)  # MB/s
        
        return stats


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Smart Keyframe Extractor - å¹¶å‘å‹åŠ›æµ‹è¯•å·¥å…·")
    print("=" * 60)
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰
    import argparse
    parser = argparse.ArgumentParser(description='å¹¶å‘å‹åŠ›æµ‹è¯•å·¥å…·')
    parser.add_argument('--video-dirs', nargs='+', default=['videos/'], 
                       help='è§†é¢‘æ–‡ä»¶ç›®å½•åˆ—è¡¨')
    parser.add_argument('--max-workers', type=int, default=None,
                       help='æœ€å¤§å¹¶å‘æ•°')
    parser.add_argument('--iterations', type=int, default=1,
                       help='æµ‹è¯•è¿­ä»£æ¬¡æ•°')
    parser.add_argument('--test-type', choices=['concurrent', 'sustained'], 
                       default='concurrent', help='æµ‹è¯•ç±»å‹')
    parser.add_argument('--duration', type=int, default=10,
                       help='æŒç»­æµ‹è¯•æ—¶é•¿(åˆ†é’Ÿ)')
    parser.add_argument('--qps', type=float, default=1.0,
                       help='æŒç»­æµ‹è¯•ç›®æ ‡QPS')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = ConcurrentStressTester(max_workers=args.max_workers)
    
    # å®šä¹‰æµ‹è¯•é…ç½®
    test_configs = [
        {"name": "standard", "k": 5, "resolution": "original"},
        {"name": "fast", "k": 5, "resolution": "720p"},
        {"name": "ultra_fast", "k": 3, "resolution": "480p"},
    ]
    
    try:
        if args.test_type == 'concurrent':
            # å¹¶å‘æµ‹è¯•
            results = tester.run_concurrent_test(
                video_dirs=args.video_dirs,
                test_configs=test_configs,
                iterations=args.iterations
            )
        else:
            # æŒç»­è´Ÿè½½æµ‹è¯•
            results = tester.run_sustained_load_test(
                video_dirs=args.video_dirs,
                test_config=test_configs[0],  # ä½¿ç”¨ç¬¬ä¸€ä¸ªé…ç½®
                duration_minutes=args.duration,
                target_qps=args.qps
            )
        
        # æ‰“å°ç»“æœæ‘˜è¦
        tester.print_summary(results)
        
    except KeyboardInterrupt:
        logger.warning("æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"æµ‹è¯•å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
